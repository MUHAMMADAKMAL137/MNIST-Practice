{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX1csw7gd5GZ+tLPLyQJNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUHAMMADAKMAL137/MNIST-Practice/blob/main/Layer_weight_creation_in_build(input_shape).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sggQWJhqv0je"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Linear(keras.layers.Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "  def __init__(self, units=32):\n",
        "    super().__init__()\n",
        "    self.units = units\n",
        "  def build(self, input_shape):\n",
        "    self.w =self.add_weight(shape=(input_shape-1, self.units), iInitializer = \"random_normal\", trainable= true)\n",
        "    self.b =self.add_weight(shape=(self.unit,),Initializer= \"random_normal\", trainable = true )\n",
        "  def call(self, inputs):\n",
        "    return tf.mutmul(inputs, self.w) + self.b\n",
        "    # Instantiate our layer.\n",
        "    linear_layer = linear(4)\n",
        "    # This will also call `build(input_shape)` and create the weights.\n",
        "    y = linear_layer(tf.ones((2,2)))\n",
        "#     In the code you provided, a class called `Linear` is defined as a subclass of `keras.layers.Layer`. This class represents a linear layer in a neural network, with the equation `y = w.x + b`. Here's a breakdown of the code:\n",
        "\n",
        "# 1. The `__init__` method is the constructor of the class. It initializes the object and sets the number of units (neurons) for the linear layer.\n",
        "\n",
        "# 2. The `build` method is called when the layer is connected to an input for the first time. It is used to define the weights of the layer. Within this method, `self.w` and `self.b` are created as trainable weights using `self.add_weight`. The shape of `self.w` is `(input_shape-1, self.units)` where `input_shape` represents the number of input features. The shape of `self.b` is `(self.units,)`, matching the number of units specified.\n",
        "\n",
        "# 3. The `call` method defines the forward pass of the layer. It takes the input `inputs`, performs matrix multiplication between the input and the weight matrix `self.w`, and adds the bias `self.b`. The result is returned as the output of the layer.\n",
        "\n",
        "# 4. After the class definition, an instance of the `Linear` layer called `linear_layer` is created with `units=4`.\n",
        "\n",
        "# 5. Finally, the code applies the `linear_layer` to a tensor of ones with shape `(2, 2)`. This is done by calling `linear_layer(tf.ones((2, 2)))`. The result is stored in `y`.\n",
        "\n",
        "# In summary, the code defines a custom linear layer that can be used as a building block in a neural network. It sets up the layer's weights in the `build` method and performs the forward pass computation in the `call` method. The instance of the `Linear` layer is then used to apply the layer to a tensor of ones, generating the output `y`."
      ],
      "metadata": {
        "id": "m9CWW1sFypOX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLES4kwpyziA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}